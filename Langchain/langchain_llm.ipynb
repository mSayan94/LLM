{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load an LLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "model_name = os.getenv(\"HUGGINGFACE_MODEL_NAME\")\n",
    "huggingface_llm_model = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=api_token, repo_id=model_name, model_kwargs={\n",
    "        \"max_length\": 128, \n",
    "        \"temperature\": 0.5}\n",
    ")\n",
    "print(huggingface_llm_model.predict(\"Suggest me some amazing places to visit in Delhi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_openai_model = AzureChatOpenAI(\n",
    "    azure_deployment =\"gpt-35-turbo-16k\",\n",
    "    azure_endpoint =os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_key =os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "print(azure_openai_model.predict(\"What is the capital of India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],template=\"Tell me the capital of {country}\")\n",
    "prompt_template.format(country = \"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=azure_openai_model, prompt=prompt_template)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***So, the Final code block looks like this***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "model_name = os.getenv(\"HUGGINGFACE_MODEL_NAME\")\n",
    "\n",
    "# llm_model = HuggingFaceHub(\n",
    "#     huggingfacehub_api_token = api_token, repo_id=model_name, model_kwargs={\"max_length\": 128, \"temperature\": 0.5}\n",
    "# )\n",
    "\n",
    "azure_openai_model = AzureChatOpenAI(\n",
    "    azure_deployment =\"gpt-35-turbo-16k\",\n",
    "    azure_endpoint =os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_key =os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],template=\"Tell me the capital of {country}\")\n",
    "chain = LLMChain(llm=azure_openai_model, prompt=prompt_template)\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining multiple chains using Simple sequential chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "capital_template = PromptTemplate(input_variables=['country'], template=\"Please tell me the capital of {country}\")\n",
    "capital_chain = LLMChain(llm=azure_openai_model, prompt=capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'], template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=azure_openai_model, prompt=famous_template)\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here's a step-by-step approach for creating a Simple Sequential LLM Chain without relying on the Hugging Face library:\n",
    "\n",
    "   1. **Import Required Modules:**\n",
    "      - Import the necessary modules, including classes like `PromptTemplate`, `LLMChain`, and `SimpleSequentialChain`.\n",
    "\n",
    "      ```python\n",
    "      from your_custom_module.prompts import PromptTemplate\n",
    "      from your_custom_module.chains import LLMChain, SimpleSequentialChain\n",
    "      ```\n",
    "\n",
    "   2. **Set Up Language Model:**\n",
    "      - Set up your language model, whether it's a custom implementation or another library.\n",
    "      - Configure any necessary parameters for the language model.\n",
    "\n",
    "      ```python\n",
    "      from your_custom_module.models import YourLanguageModel\n",
    "\n",
    "      llm_model = YourLanguageModel(model_args={\"max_length\": 128, \"temperature\": 0.5})\n",
    "      ```\n",
    "\n",
    "   3. **Create Prompt Templates:**\n",
    "      - Define prompt templates for input variables and desired prompts.\n",
    "\n",
    "      ```python\n",
    "      first_template = PromptTemplate(input_variables=['var1'], template=\"Your Custom template {var1}\")\n",
    "      second_template = PromptTemplate(input_variables=['var2'], template=\"Your Custom template {var2}\")\n",
    "      ```\n",
    "\n",
    "   4. **Create LLM Chains:**\n",
    "      - Instantiate LLM Chains using the language model and prompt templates.\n",
    "\n",
    "      ```python\n",
    "      first_chain = LLMChain(llm=llm_model, prompt=first_template)\n",
    "      second_chain = LLMChain(llm=llm_model, prompt=second_template)\n",
    "      ```\n",
    "\n",
    "   5. **Create Simple Sequential Chain:**\n",
    "      - Combine individual chains into a Simple Sequential Chain.\n",
    "\n",
    "      ```python\n",
    "      chain = SimpleSequentialChain(chains=[first_chain, second_chain])\n",
    "      ```\n",
    "\n",
    "   6. **Run the Chain:**\n",
    "      - Execute the chain with a specific input.\n",
    "\n",
    "      ```python\n",
    "      result = chain.run(\"YourInputValue\")\n",
    "      ```\n",
    "\n",
    "      The `run` method initiates the sequential execution, starting with the first chain and passing the result to the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***So, the Final code block looks like this***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "model_name = os.getenv(\"HUGGINGFACE_MODEL_NAME\")\n",
    "\n",
    "# llm_model = HuggingFaceHub(\n",
    "#     huggingfacehub_api_token = api_token, repo_id=model_name, model_kwargs={\"max_length\": 128, \"temperature\": 0.5}\n",
    "# )\n",
    "\n",
    "azure_openai_model = AzureChatOpenAI(\n",
    "    azure_deployment =\"gpt-35-turbo-16k\",\n",
    "    azure_endpoint =os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_key =os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "capital_template = PromptTemplate(input_variables=['country'], template=\"Please tell me the capital of {country}\")\n",
    "capital_chain = LLMChain(llm=azure_openai_model, prompt=capital_template)\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'], template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=azure_openai_model, prompt=famous_template)\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "chain.run(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "\n",
    "# api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "# model_name = os.getenv(\"HUGGINGFACE_MODEL_NAME\")\n",
    "\n",
    "# llm_model = HuggingFaceHub(\n",
    "#     huggingfacehub_api_token = api_token, repo_id=model_name, model_kwargs={\"max_length\": 128, \"temperature\": 0.5}\n",
    "# )\n",
    "\n",
    "azure_openai_model = AzureChatOpenAI(\n",
    "    azure_deployment =\"gpt-35-turbo-16k\",\n",
    "    azure_endpoint =os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_key =os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "capital_template = PromptTemplate(input_variables=['country'], template=\"Please tell me the capital of {country}\")\n",
    "capital_chain = LLMChain(llm=azure_openai_model, prompt=capital_template, output_key=\"capital\")\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'], template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain = LLMChain(llm=azure_openai_model, prompt=famous_template,output_key=\"places\")\n",
    "\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chain], input_variables=['country'], output_variables=['capital',\"places\"])\n",
    "chain({'country':\"India\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatModels with Chat OpenAI\n",
    "\n",
    "There are three schemas with respect to ChatOpenAI:\n",
    "\n",
    "- **Human message**: This is the input that the user gives to the chatbot.\n",
    "- **System message**: This is the default message that the chatbot opens with. It is related to the domain of the chatbot.\n",
    "- **AI message**: This is the output that the chatbot gives to the user. It is generated by the AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI go on a diet? Because it had too many bytes!\"\\n2. \"Why did the AI break up with its robot partner? It said they just didn\\'t have the right algorithms!\"\\n3. \"How does an AI apologize? It says \\'I\\'m sorry, I made a bit of a glitch-take!\"\\n4. \"Why did the AI get kicked out of the comedy club? It kept telling \\'Ctrl+Alt+Delete\\' jokes!\"\\n5. \"What did one AI say to the other at a party? \\'I\\'m feeling a bit byte-sized, let\\'s go grab some chips!\\'\"\\n6. \"Why did the AI become a stand-up comedian? It wanted to program laughter into its algorithms!\"\\n7. \"Why did the AI take up singing? It wanted to hit all the high notes, but it ended up just making a lot of \\'byte\\'-ful sounds!\"\\n8. \"Why did the AI start a band? It wanted to create music that really \\'resonated\\' with its data!\"\\n9. \"Why did the AI become a magician? It loved performing \\'data\\'illusions and \\'byte\\'-sized tricks!\"\\n10. \"What\\'s an AI\\'s favorite type of comedy? Stand-up \\'byte\\'!\"\\n\\nRemember, comedy is subjective, so these punchlines may vary in their effectiveness depending on personal taste.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "azure_chat_llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-35-turbo-16k\",\n",
    "    azure_endpoint=os.getenv(\"OPENAI_API_BASE\"),\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "azure_chat_llm([\n",
    "    SystemMessage(content=\"You are a Comedian AI assistant\"),\n",
    "    HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
